#+TITLE: Assignment 1
#+AUTHOR: Jason Medcoff

#+LaTeX_HEADER: \usepackage{geometry}
#+LaTeX_HEADER: \geometry{a4paper}
#+OPTIONS: toc:nil

#+BEGIN_SRC C :tangle yes :exports none
#include <stdio.h>
#include <omp.h>
#include <stdlib.h>
#+END_SRC

#+BEGIN_SRC C :tangle yes :exports none
const int N = 10;
const int M = 100;
#+END_SRC

* Matrix Construction

We will begin by considering the actions necessary to construct the $N
\times N$ integer matrix. As we want to fill the matrix with random
integers up to some limit, it makes sense to begin by thinking about
how to divide this task. We'll start with a naive function to fill our
matrix with the desired values.

#+BEGIN_SRC C :tangle yes
void fill_matrix(int arr[][N], int M) {
  srand(1234);
  for (int i=0; i<N; i++) {
    for (int j=0; j<N; j++) {
      arr[i][j] = rand() % M;
    }
  }
}
#+END_SRC

Next, in order to parallelize, we consider the nested loop. We know C
is row-major, so we would like to parallelize on the outer loop.

#+BEGIN_SRC C :tangle yes
void fill_matrix_p1(int arr[][N], int M) {
  srand(1234);
  int n_threads = omp_get_num_threads();
  #pragma omp parallel 
  {
  int tid = omp_get_thread_num();
  int start = tid*N/n_threads;
  int end = (tid+1)*N/n_threads;
  int i, j;
  for (i=start; i<end; i++) {
    for (j=0; j<N; j++) {
      arr[i][j] = rand() % M;
    }
  }
  }
}
#+END_SRC

For another variant, we can utilize the ~for~ construct.

#+BEGIN_SRC C :tangle yes
void fill_matrix_p2(int arr[][N], int M) {
  srand(1234);
  #pragma omp parallel for
  for (int i=0; i<N; i++) {
    for (int j=0; j<N; j++) {
      arr[i][j] = rand() % M;
    }
  }
}

#+END_SRC

* Finding the Maximum

Next, we would like to find the maximum value in the
matrix. Intuitively, this is where the omp ~reduction~ clause will
shine, but we still begin with a serial version.

#+BEGIN_SRC C :tangle yes
int max_in_matrix(int arr[][N]) {
  int max = arr[0][0];
  for (int i=0; i<N; i++) {
    for (int j=0; j<N; j++) {
      if (arr[i][j] > max)
	max = arr[i][j];
    }
  }
  return max;
}
#+END_SRC

The next version assigns work explicitly among each thread.

#+BEGIN_SRC C :tangle yes
int max_in_matrix_p1(int arr[][N]) {
  int max = arr[0][0];
  int n_threads = omp_get_num_threads();
  #pragma omp parallel 
  {
  int tid = omp_get_thread_num();
  int start = tid*N/n_threads;
  int end = (tid+1)*N/n_threads;
  for (int i=start; i<end; i++) {
    for (int j=0; j<N; j++) {
      if (arr[i][j] > max) {
	#pragma omp critical
	max = arr[i][j];
      }
    }
  }
  }
  return max;
}
#+END_SRC

Next, an intelligent version can be constructed by using a parallel
for.

#+BEGIN_SRC C :tangle yes
int max_in_matrix_p2(int arr[][N]) {
  int max = arr[0][0];
  #pragma omp parallel for
  for (int i=0; i<N; i++) {
    for (int j=0; j<N; j++) {
      if (arr[i][j] > max) {
	#pragma omp critical
	max = arr[i][j];
      }
    }
  }
  return max;
}
#+END_SRC

Finally, reduction is used to abstract away the task of computing the
maximum between threads.

#+BEGIN_SRC C :tangle yes
int max_in_matrix_p3(int arr[][N]) {
  int max = arr[0][0];
  #pragma omp parallel for reduction(max:max)
  for (int i=0; i<N; i++) {
    for (int j=0; j<N; j++) {
      if (arr[i][j] > max)
	max = arr[i][j];
    }
  }
  return max;
}
#+END_SRC

#+BEGIN_SRC C :tangle yes :exports none
int main(void) {
  int A[N][N];
  fill_matrix_p1(A, M);
  for (int i=0; i<N; i++) {
    for (int j=0; j<N; j++) {
     printf("%d ", A[i][j]);
    }
    printf("\n");
  }
  int maximum = max_in_matrix(A);
  printf("%d\n", maximum);
  return 0;
} // at this point, the random matrix
  // is being successfully created
  // and the maximum output as well.
#+END_SRC

* Histograms
